{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "6142ff1e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ðŸ§¹ Data Cleaning and Preprocessing â€“ Task 1\n",
    "# Dataset: Sales Data (raw_sales_data.xlsx)\n",
    "\n",
    "# Step 1: Import libraries\n",
    "import pandas as pd\n",
    "import numpy as np\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "6fab998a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âœ… Dataset loaded successfully!\n",
      "Initial shape: (24, 11)\n"
     ]
    }
   ],
   "source": [
    "# Step 2: Load dataset\n",
    "df = pd.read_excel('E:/Internship/DA Intern/Task1/dataset/retaildata1.xlsx')\n",
    "print(\"âœ… Dataset loaded successfully!\")\n",
    "print(\"Initial shape:\", df.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "78c4f25c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Dataset Info ---\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 24 entries, 0 to 23\n",
      "Data columns (total 11 columns):\n",
      " #   Column            Non-Null Count  Dtype         \n",
      "---  ------            --------------  -----         \n",
      " 0   Transaction ID    24 non-null     object        \n",
      " 1   Customer ID       24 non-null     object        \n",
      " 2   Category          24 non-null     object        \n",
      " 3   Item              17 non-null     object        \n",
      " 4   Price Per Unit    20 non-null     float64       \n",
      " 5   Quantity          21 non-null     float64       \n",
      " 6   Total Spent       21 non-null     float64       \n",
      " 7   Payment Method    24 non-null     object        \n",
      " 8   Location          24 non-null     object        \n",
      " 9   Transaction Date  24 non-null     datetime64[ns]\n",
      " 10  Discount Applied  16 non-null     float64       \n",
      "dtypes: datetime64[ns](1), float64(4), object(6)\n",
      "memory usage: 2.2+ KB\n",
      "None\n",
      "\n",
      "--- Missing Values ---\n",
      "Transaction ID      0\n",
      "Customer ID         0\n",
      "Category            0\n",
      "Item                7\n",
      "Price Per Unit      4\n",
      "Quantity            3\n",
      "Total Spent         3\n",
      "Payment Method      0\n",
      "Location            0\n",
      "Transaction Date    0\n",
      "Discount Applied    8\n",
      "dtype: int64\n",
      "\n",
      "--- Sample Records ---\n",
      "  Transaction ID Customer ID       Category          Item  Price Per Unit  \\\n",
      "0    TXN_6867343     CUST_09     Patisserie   Item_10_PAT            18.5   \n",
      "1    TXN_3731986     CUST_22  Milk Products  Item_17_MILK            29.0   \n",
      "2    TXN_9303719     CUST_02       Butchers   Item_12_BUT            21.5   \n",
      "3    TXN_9458126     CUST_06      Beverages   Item_16_BEV            27.5   \n",
      "4    TXN_4575373     CUST_05           Food   Item_6_FOOD            12.5   \n",
      "\n",
      "   Quantity  Total Spent  Payment Method Location Transaction Date  \\\n",
      "0      10.0        185.0  Digital Wallet   Online       2024-04-08   \n",
      "1       9.0        261.0  Digital Wallet   Online       2023-07-23   \n",
      "2       2.0         43.0     Credit Card   Online       2022-10-05   \n",
      "3       9.0        247.5     Credit Card   Online       2022-05-07   \n",
      "4       7.0         87.5  Digital Wallet   Online       2022-10-02   \n",
      "\n",
      "   Discount Applied  \n",
      "0               1.0  \n",
      "1               1.0  \n",
      "2               0.0  \n",
      "3               NaN  \n",
      "4               0.0  \n"
     ]
    }
   ],
   "source": [
    "\n",
    "# Step 3: Inspect dataset\n",
    "print(\"\\n--- Dataset Info ---\")\n",
    "print(df.info())\n",
    "\n",
    "print(\"\\n--- Missing Values ---\")\n",
    "print(df.isnull().sum())\n",
    "\n",
    "print(\"\\n--- Sample Records ---\")\n",
    "print(df.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "901fc734",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "âœ… Missing values handled successfully!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Sabarinathan S\\AppData\\Local\\Temp\\ipykernel_2304\\3321206713.py:4: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
      "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
      "\n",
      "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
      "\n",
      "\n",
      "  df[col].fillna(df[col].mode()[0], inplace=True)\n",
      "C:\\Users\\Sabarinathan S\\AppData\\Local\\Temp\\ipykernel_2304\\3321206713.py:6: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
      "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
      "\n",
      "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
      "\n",
      "\n",
      "  df[col].fillna(df[col].mean(), inplace=True)\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# Step 4: Handle missing values\n",
    "for col in df.columns:\n",
    "    if df[col].dtype == 'object':\n",
    "        df[col].fillna(df[col].mode()[0], inplace=True)\n",
    "    else:\n",
    "        df[col].fillna(df[col].mean(), inplace=True)\n",
    "print(\"\\nâœ… Missing values handled successfully!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "269cae52",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âœ… Removed 0 duplicate rows.\n"
     ]
    }
   ],
   "source": [
    "# Step 5: Remove duplicates\n",
    "before = df.shape[0]\n",
    "df.drop_duplicates(inplace=True)\n",
    "after = df.shape[0]\n",
    "print(f\"âœ… Removed {before - after} duplicate rows.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "b1444ebd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âœ… Text values standardized (lowercase, trimmed).\n",
      "âœ… Converted date columns to dd-mm-yyyy: ['Transaction Date']\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# Step 6: Standardize text columns\n",
    "text_cols = df.select_dtypes(include='object').columns\n",
    "for col in text_cols:\n",
    "    df[col] = df[col].astype(str).str.strip().str.lower()\n",
    "print(\"âœ… Text values standardized (lowercase, trimmed).\")\n",
    "\n",
    "# Step 7: Convert date columns\n",
    "date_cols = [col for col in df.columns if 'date' in col.lower()]\n",
    "for col in date_cols:\n",
    "    df[col] = pd.to_datetime(df[col], errors='coerce', dayfirst=True)\n",
    "print(f\"âœ… Converted date columns to dd-mm-yyyy: {date_cols}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "3cb1ae77",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âœ… Column names standardized (lowercase, underscores).\n",
      "âœ… Data types corrected where applicable.\n"
     ]
    }
   ],
   "source": [
    "# Step 8: Rename columns\n",
    "df.columns = df.columns.str.lower().str.replace(' ', '_').str.replace('-', '_')\n",
    "print(\"âœ… Column names standardized (lowercase, underscores).\")\n",
    "\n",
    "# Step 9: Fix data types\n",
    "if 'quantity' in df.columns:\n",
    "    df['quantity'] = df['quantity'].astype(int)\n",
    "if 'sales' in df.columns:\n",
    "    df['sales'] = df['sales'].astype(float)\n",
    "print(\"âœ… Data types corrected where applicable.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "a134d801",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Cleaned Data Info ---\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 24 entries, 0 to 23\n",
      "Data columns (total 11 columns):\n",
      " #   Column            Non-Null Count  Dtype         \n",
      "---  ------            --------------  -----         \n",
      " 0   transaction_id    24 non-null     object        \n",
      " 1   customer_id       24 non-null     object        \n",
      " 2   category          24 non-null     object        \n",
      " 3   item              24 non-null     object        \n",
      " 4   price_per_unit    24 non-null     float64       \n",
      " 5   quantity          24 non-null     int32         \n",
      " 6   total_spent       24 non-null     float64       \n",
      " 7   payment_method    24 non-null     object        \n",
      " 8   location          24 non-null     object        \n",
      " 9   transaction_date  24 non-null     datetime64[ns]\n",
      " 10  discount_applied  24 non-null     float64       \n",
      "dtypes: datetime64[ns](1), float64(3), int32(1), object(6)\n",
      "memory usage: 2.1+ KB\n",
      "None\n",
      "\n",
      "ðŸŽ‰ Cleaned dataset saved to 'cleaned_data/cleaned_sales_data.csv'!\n",
      "\n",
      "--- Summary of Cleaning ---\n",
      "Missing Values Handled: True\n",
      "Duplicates Removed: 0\n",
      "Text Columns Standardized: ['Transaction ID', 'Customer ID', 'Category', 'Item', 'Payment Method', 'Location']\n",
      "Date Columns Converted: ['Transaction Date']\n",
      "Columns Renamed: True\n",
      "Data Types Fixed: True\n"
     ]
    }
   ],
   "source": [
    "# Step 10: Verify results\n",
    "print(\"\\n--- Cleaned Data Info ---\")\n",
    "print(df.info())\n",
    "\n",
    "# Step 11: Save cleaned dataset\n",
    "df.to_csv('cleaned_data/cleaned_sales_data.csv', index=False)\n",
    "print(\"\\nðŸŽ‰ Cleaned dataset saved to 'cleaned_data/cleaned_sales_data.csv'!\")\n",
    "\n",
    "# Step 12: Summary of cleaning process\n",
    "summary = {\n",
    "    \"Missing Values Handled\": True,\n",
    "    \"Duplicates Removed\": before - after,\n",
    "    \"Text Columns Standardized\": list(text_cols),\n",
    "    \"Date Columns Converted\": date_cols,\n",
    "    \"Columns Renamed\": True,\n",
    "    \"Data Types Fixed\": True\n",
    "}\n",
    "\n",
    "print(\"\\n--- Summary of Cleaning ---\")\n",
    "for k, v in summary.items():\n",
    "    print(f\"{k}: {v}\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
